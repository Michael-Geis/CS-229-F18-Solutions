{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PS2-1: Training Stability of Logistic Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The code in src/p01_lr.py trains a logistic regression algorithm on two different datasets, A and B in /data/ds1_{a/b}.csv. This problem investigates the difference in performance of the model on the two datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (A)\n",
    "#### What is the main difference in training the model on dataset A vs B?\n",
    "\n",
    "The training converges on dataset A while it seems to fail to converge on dataset B."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (B)\n",
    "#### Provide an explanation for the difference in behavior between the two datasets.\n",
    "\n",
    "First, we make a plot of both datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PS2.src import util\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "Xa , Ya = util.load_csv('.PS2/data/ds1_a.csv')\n",
    "Xb , Yb = util.load_csv('.PS2/data/ds1_b.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Find the spread of the x_0 coordinate in both datasets.\n",
    "x0a_spread = Xa[:,0].max() - Xa[:,0].min()\n",
    "x1a_spread = Xa[:,1].max() - Xa[:,1].min()\n",
    "\n",
    "x0b_spread = Xb[:,0].max() - Xb[:,0].min()\n",
    "x1b_spread = Xb[:,1].max() - Xb[:,1].min()\n",
    "\n",
    "# Calculate 20% of the spread as margin on either side \n",
    "\n",
    "# Calculate 20% of the spread as margin on either side \n",
    "x0a_margin = x0a_spread / 5\n",
    "x1a_margin = x1a_spread / 5 \n",
    "\n",
    "\n",
    "x0b_margin = x0b_spread / 5\n",
    "x1b_margin = x1b_spread / 5 \n",
    "\n",
    "\n",
    "fig , axa = plt.subplots()\n",
    "\n",
    "# Set the x and y ranges\n",
    "axa.set_xlim(Xa[:,0].min() - x0a_margin , Xa[:,0].max() + x0a_margin)\n",
    "axa.set_ylim(Xa[:,1].min() - x1a_margin , Xa[:,1].max() + x1a_margin)\n",
    "\n",
    "axa.set_title('plot of dataset a')\n",
    "\n",
    "axa.plot(Xa[Ya == 1, 0], Xa[Ya == 1, 1], 'bx', linewidth=2, label='positive examples')\n",
    "axa.plot(Xa[Ya == -1, 0], Xa[Ya == -1,1], 'go', linewidth=2, label='negative examples')\n",
    "\n",
    "# Let's also plot the mean of the positive and negative examples.\n",
    "m , n = Xa.shape\n",
    "xa_pos_mean = 1/(2*m) * np.sum(Xa[Ya==1,:], axis=0)\n",
    "xa_neg_mean = 1/(2*m) * np.sum(Xa[Ya==-1,:], axis=0)\n",
    "\n",
    "axa.plot(xa_pos_mean[0], xa_pos_mean[1], 'yo', linewidth=10, label = 'positive mean')\n",
    "axa.plot(xa_neg_mean[0], xa_neg_mean[1], 'yx', linewidth=10, label = 'negative mean')\n",
    "\n",
    "axa.legend()\n",
    "\n",
    "\n",
    "plt.savefig('ds1_a.png', format='png')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(f'{100 * Xa[Ya==1,:].shape[0]/Xa.shape[0] } percent of dataset a examples are positive.')\n",
    "print(f'The initial gradient of the loss function is {xa_pos_mean - xa_neg_mean} for dataset a')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
